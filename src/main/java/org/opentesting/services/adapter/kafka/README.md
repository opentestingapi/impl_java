# Kafka

Using consumer and producer to perform inject and check

### Configuration Inject

* please use sourcefile to store message to send
* StringSerializer is default, should be fine as we send file content directly
* please use empty user and password for unprotected topics
* random data replacement processed for: sourcefile

| custom parameter | description | example |
|-----|-----|-----|
| topic | topic to produce | mytopic1 |
| header | define headers (key-value file), please use #username#, #password# or replacement keys as placeholders (optional) | source_kafka_headers_1.json |
| security.protocol | security protocol used in combination with user and password (optional) | SASL_PLAINTEXT |
| sasl.mechanism | sasl mechanism used in combination with user and password (optional) | SCRAM-SHA-512 |
| login.module | login module used in combination with user and password (optional) | org.apache.kafka.common.security.scram.ScramLoginModule |
| jwtpost | POST to request token (optional) | https://server/env/gui/auth/realms/myrealm/protocol/openid-connect/token |
| jwtparam | parameters for the request; please use #username#, #password# or replacement keys as placeholders (for example #jwtpassword# could be used and will be decrypted automatically) (optional) | client_id=myclientid&grant_type=password&username=#jwtuser#&password=#jwtpassword# |
| jwtheader | header fields to be added to the jwt request (optional) | myHeaders.json |
| jwtuser | might be used to specify the user in dedicated field (optional) | myuser |
| jwtpassword | might be used to specify the password in dedicated field (optional) | myPossibillyEncryptedPassword |
| kafkaheaderjwt | define the kafka header key for requested JWT (optional) | accessToken |
| senddelay | milliseconds to delay the send, helpful if kafka consumer initialization is to slow (default: not used) | 15000 |
| producer property | you can use any of the available Kafka producer properties (optional) | see link |

https://docs.confluent.io/platform/current/installation/configuration/producer-configs.html

```
{
        "injectid": "inject-kafka-1",
        "cron" : [ "0 * * * * ?" , "12 * * * * ?", "21 * * * * ?", "30 * * * * ?", "41 * * * * ?", "52 * * * * ?" ],
        "active" : true,
        "service" : {
            "type": "kafka",
            "connectstring": "localhost:9092",
            "username": "",
            "password": "",
            "custom": [
               {
                  "key": "topic",
                  "value": "mytopic1"
               },
               {
                  "key": "security.protocol",
                  "value": "protocol"
               },
               {
                  "key": "sasl.mechanism",
                  "value": "mechanism"
               },
               {
                  "key": "login.module",
                  "value": "module"
               },
               {
                  "key": "header",
                  "value": "source_kafka_headers_1.json"
               },
               {
                  "key": "jwtuser",
                  "value": "jwtuser"
               },
               {
                  "key": "jwtpassword",
                  "value": "jwtpassword"
               },
               {
                  "key": "jwtpost",
                  "value": "jwtposturl"
               },
               {
                  "key": "jwtparam",
                  "value": "jwtparameters"
               },
               {
                  "key": "jwtheader",
                  "value": "jwtheaders"
               }
            ]
         },        
        "sourcefile" : "source_kafka_1.txt",        
        "timetolive": "5d",
        "checks" : [ "check-kafka-1" ],
        "replacements" : [...]
}
```

### Configuration Check

* validation 'request' not required
* StringDeserializer is default, should be fine as we do only String validations
* please use validation 'response' to define expected JSON result(s)
* expectedtype could be 'equals', 'contains', 'containsnot', 'containsoneof'
* random data replacement processed for: 'response'
* please use empty user and password for unprotected topics
* injects executed after successful check (please do not create infinite loops)
* please use dataextraction to transfer JSON result (only JSON!) attributes to random data for later usage

| custom parameter | description | example |
|-----|-----|-----|
| topic | topic to consume | mytopic1 |
| group.id | unique group.id for the consumer, will be random if not specified | myUniqueIdForMyTesCase0001 |
| security.protocol | security protocol used in combination with user and password (optional) | SASL_PLAINTEXT |
| sasl.mechanism | sasl mechanism used in combination with user and password (optional) | SCRAM-SHA-512 |
| login.module | login module used in combination with user and password (optional) | org.apache.kafka.common.security.scram.ScramLoginModule |
| stopexpectedlog | hide check compare log actual vs expected (required for high load topics), default = false | true |
| consumer property | you can use any of the available Kafka consumer properties (optional) | see link |

https://docs.confluent.io/platform/current/installation/configuration/consumer-configs.html

```
{
        "checkid": "check-kafka-1",  
        "active": true,
        "service": {
            "type": "kafka",
            "connectstring": "localhost:9092",
            "username": "",
            "password": "",
            "custom": [
               {
                  "key": "topic",
                  "value": "mytopic1"
               },
               {
                  "key": "group.id",
                  "value": "e2etests"
               },
               {
                  "key": "security.protocol",
                  "value": "protocol"
               },
               {
                  "key": "sasl.mechanism",
                  "value": "mechanism"
               },
               {
                  "key": "login.module",
                  "value": "module"
               }
            ]
         },
         "validations": [
            {
               "order": 1,
               "request": "",
               "response": [ "check_kafka_1.txt" ],
               "type": "contains"
            }
         ],        
        "maxwaittime": "10m",
        "mandatory": false,
        "injects": [ "inject-rest-2" ],
        "checks": [ "check-rest-2" ],
        "dataextraction": [ 
            {
               "attribute": "test",
               "source": "payload",
               "target": "#check-kafka-1.test#"
            },{
               "attribute": "testheader",
               "source": "header",
               "target": "#check-kafka-1.testheader#",
               "regex": ".*test"
            }
         ]
}
```
