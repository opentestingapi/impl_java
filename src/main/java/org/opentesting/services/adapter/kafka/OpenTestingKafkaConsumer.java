package org.opentesting.services.adapter.kafka;

import java.util.HashMap;
import java.util.Map;
import java.util.Set;
import java.util.UUID;

import org.opentesting.dto.TestCaseCustomParameterDTO;
import org.opentesting.dto.TestCaseServiceDTO;
import org.opentesting.dto.api1dot0.TestCaseServiceDTOapi1dot0;
import org.opentesting.services.adapter.Adapter;
import org.opentesting.services.encryption.Encryption;
import org.opentesting.services.execution.TestCheck;
import org.opentesting.services.prometheus.Prometheus;
import org.opentesting.util.LogExecutionTime;

import org.apache.kafka.clients.consumer.ConsumerConfig;
import org.apache.kafka.common.serialization.StringDeserializer;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.kafka.listener.ContainerProperties;
import org.springframework.kafka.listener.KafkaMessageListenerContainer;
import org.springframework.stereotype.Component;

import brave.kafka.clients.KafkaTracing;
import lombok.extern.slf4j.Slf4j;

@Component
@Slf4j
public class OpenTestingKafkaConsumer {

    private static final String SECURITY_PROTOCOL = "security.protocol";
    private static final String SASL_MECHANISM = "sasl.mechanism";

    @Autowired
    private TestCheck testCheck;

    @Autowired
    private Prometheus prometheus;

    @Autowired
    private Encryption encryption;

    @Autowired
    private KafkaTracing kafkaTracing;

    @Autowired
    private KafkaTrace kafkaTrace;

    @Value("${kafka.reconnect.backoff.max.ms}")
    private int reconnectBackoffMaxMs;

    @Value("${kafka.reconnect.backoff.ms}")
    private int reconnectBackoffMs;

    //we need to handle everything as a string to do simple string checks
    private Map<String, KafkaMessageListenerContainer<String, String>> createdConsumers = new HashMap<>();

    @LogExecutionTime
    public void createConsumer(String testid, TestCaseServiceDTO service, Adapter adapter) {
       
        //we will not share between test ids, they need to use different group.ids
        String key = createUniqueKey(testid, service);
        if (createdConsumers.containsKey(key)) {
            log.info("kafka consumer already exists: "+key);
            return;
        }

        //validation
        String groupid = service.getCustom("group.id").getStringValue();
        if (groupid == null || groupid.isEmpty()) {            
            groupid = UUID.randomUUID().toString();
            log.warn(testid+": using group.id="+groupid);
        }

        //default properties
        Map<String, Object> props = new HashMap<>();
        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, service.getConnectstring());
        props.put(ConsumerConfig.GROUP_ID_CONFIG, groupid);
        props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class);
        props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class);  
        props.put(ConsumerConfig.RECONNECT_BACKOFF_MS_CONFIG, reconnectBackoffMs);
        props.put(ConsumerConfig.RECONNECT_BACKOFF_MAX_MS_CONFIG, reconnectBackoffMaxMs);

        //user and password
        if (service.getUsername() != null && service.getUsername().length() > 0) {
            props.put(SECURITY_PROTOCOL, service.getCustom(SECURITY_PROTOCOL).getValue());
            log.warn(testid+": using "+SECURITY_PROTOCOL+"="+service.getCustom(SECURITY_PROTOCOL).getValue());
            props.put(SASL_MECHANISM, service.getCustom(SASL_MECHANISM).getValue());
            log.warn(testid+": using "+SASL_MECHANISM+"="+service.getCustom(SASL_MECHANISM).getValue());
            String jassconfigPre = service.getCustom("login.module").getValue() + " required username=\"" + service.getUsername() 
            + "\" password=\"";
            props.put("sasl.jaas.config", jassconfigPre + encryption.decrypt(service.getPassword()) + "\";");
            log.warn(testid+": using sasl.jaas.config="+jassconfigPre + "***\";");
        }

        //override with custom ones
        Set<String> kapfaParameters = ConsumerConfig.configNames();
        for (TestCaseCustomParameterDTO cust : service.getCustom()) {
            if (kapfaParameters.contains(cust.getKey())) { 
                log.warn(testid+": setting consumer property "+cust.getKey()+"="+cust.getValue());
                props.put(cust.getKey(), cust.getValue()); 
            }            
        }
  
        //factory
        OpenTestingKafkaConsumerFactory fact = new OpenTestingKafkaConsumerFactory(props, kafkaTracing);

        //consumer container
        ContainerProperties containerProps = new ContainerProperties(service.getCustom("topic").getStringValue());
        containerProps.setMessageListener(new OpenTestingKafkaMessageListener(testid, service, testCheck, key, prometheus, adapter, kafkaTrace));
        KafkaMessageListenerContainer<String, String> container = new KafkaMessageListenerContainer<>(fact, containerProps);

        //start container
        container.start();

        //give it time to start
        try {
            Thread.sleep(1000);
        } catch (InterruptedException e) {
            log.warn("sleep interrupted", e);
            // Restore interrupted state...
            Thread.currentThread().interrupt();
        }

        //store
        if (container.isRunning()) createdConsumers.put(key, container);
        log.info("KafkaConsumer created: "+key);
    }

    /**
     * close consumer
     * @param testid
     * @param service
     * @param kafka
     */
    @LogExecutionTime
    public void closeConsumer(String testid, TestCaseServiceDTOapi1dot0 service, Kafka kafka) {
        String key = createUniqueKey(testid, service);
        if (createdConsumers.containsKey(key)) {
            log.info("closing kafka consumer: "+key);
            createdConsumers.get(key).destroy();
            createdConsumers.remove(key);
        }
    }

    /**
     * close consumer
     * @param testid
     */
    @LogExecutionTime
    public void closeConsumer(String testid) {
        for (Map.Entry<String, KafkaMessageListenerContainer<String, String>> entry : createdConsumers.entrySet()) {            
            if (entry.getKey().startsWith(testid+"#")) {
                log.info("closing kafka consumer: "+entry.getKey());
                entry.getValue().destroy();
            }
        }        
    }

    private String createUniqueKey(String testid, TestCaseServiceDTO service) {
        return testid+"#"+service.getConnectstring()+"#"+service.getCustom("topic").getValue()+"#"+service.getUsername()+"#"+service.getCustom("group.id").getValue();
    }

    /**
     * stop consumers
     */
    @LogExecutionTime
    public void stopConsumers() {
        //parallel stop
        createdConsumers.values().parallelStream().forEach(
                con -> {
                    try {
                        con.stop();
                        log.info("KafkaConsumer stopped: "+con.toString());
                    } catch (Exception e) {
                        log.warn("cannot stop consumer", e);
                    }
                }
        );
    }

    /**
     * start consumers
     */
    @LogExecutionTime
    public void startConsumers() {
        //parallel start
        createdConsumers.values().parallelStream().forEach(
                con -> {
                    try {
                        con.start();
                        log.info("KafkaConsumer started: "+con.toString());
                    } catch (Exception e) {
                        log.warn("cannot start consumer", e);
                    }
                }
        );
    }    

}