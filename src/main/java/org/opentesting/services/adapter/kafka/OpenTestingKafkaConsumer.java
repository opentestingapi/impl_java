package org.opentesting.services.adapter.kafka;

import java.util.HashMap;
import java.util.Map;

import org.opentesting.dto.TestCaseServiceDTO;
import org.opentesting.services.adapter.Adapter;
import org.opentesting.services.encryption.Encryption;
import org.opentesting.services.execution.TestCheck;
import org.opentesting.services.prometheus.Prometheus;
import org.opentesting.util.LogExecutionTime;

import org.apache.kafka.clients.consumer.ConsumerConfig;
import org.apache.kafka.common.serialization.StringDeserializer;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.kafka.listener.ContainerProperties;
import org.springframework.kafka.listener.KafkaMessageListenerContainer;
import org.springframework.stereotype.Component;

import brave.kafka.clients.KafkaTracing;
import lombok.extern.slf4j.Slf4j;

@Component
@Slf4j
public class OpenTestingKafkaConsumer {

    @Autowired
    private TestCheck testCheck;

    @Autowired
    private Prometheus prometheus;

    @Autowired
    private Encryption encryption;

    @Autowired
    private KafkaTracing kafkaTracing;

    @Autowired
    private KafkaTrace kafkaTrace;

    private Map<String, KafkaMessageListenerContainer<String, String>> createdConsumers = new HashMap<>();

    @LogExecutionTime
    public void createConsumer(TestCaseServiceDTO service, Adapter adapter) {
       
        String key = service.getConnectstring()+"#"+service.getCustom("topic").getValue()+"#"+service.getUsername();
        if (createdConsumers.containsKey(key)) {
            log.info("kafka consumer already exists: "+key);
            return;
        }

        //properties
        Map<String, Object> props = new HashMap<>();
        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, service.getConnectstring());
        props.put(ConsumerConfig.GROUP_ID_CONFIG, service.getCustom("group.id").getValue());
        props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class);
        props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class);        

        //user and password
        if (service.getUsername() != null && service.getUsername().length() > 0) {
            props.put("security.protocol", service.getCustom("security.protocol").getValue());
            props.put("sasl.mechanism", service.getCustom("sasl.mechanism").getValue());
            props.put("sasl.jaas.config", service.getCustom("login.module").getValue() + " required username=\"" + service.getUsername() 
                        + "\" password=\"" + encryption.decrypt(service.getPassword()) + "\";");
        }
  
        //factory
        OpenTestingKafkaConsumerFactory fact = new OpenTestingKafkaConsumerFactory(props, kafkaTracing);

        //consumer container
        ContainerProperties containerProps = new ContainerProperties(service.getCustom("topic").getValue());
        containerProps.setMessageListener(new OpenTestingKafkaMessageListener(service, testCheck, key, prometheus, adapter, kafkaTrace));
        KafkaMessageListenerContainer<String, String> container = new KafkaMessageListenerContainer<>(fact, containerProps);

        //start container
        container.start();

        //give it time to start
        try {
            Thread.sleep(1000);
        } catch (InterruptedException e) {
            log.warn("sleep interrupted", e);
            // Restore interrupted state...
            Thread.currentThread().interrupt();
        }

        //store
        if (container.isRunning()) createdConsumers.put(key, container);
        log.info("KafkaConsumer created: "+key);
    }

    /**
     * stop consumers
     */
    @LogExecutionTime
    public void stopConsumers() {
        //parallel stop
        createdConsumers.values().parallelStream().forEach(
                con -> {
                    try {
                        con.stop();
                        log.info("KafkaConsumer stopped: "+con.toString());
                    } catch (Exception e) {
                        log.warn("cannot stop consumer", e);
                    }
                }
        );
    }

    /**
     * start consumers
     */
    @LogExecutionTime
    public void startConsumers() {
        //parallel start
        createdConsumers.values().parallelStream().forEach(
                con -> {
                    try {
                        con.start();
                        log.info("KafkaConsumer started: "+con.toString());
                    } catch (Exception e) {
                        log.warn("cannot start consumer", e);
                    }
                }
        );
    }

}